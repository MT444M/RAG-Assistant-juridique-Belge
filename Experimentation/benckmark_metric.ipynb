{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from tqdm.autonotebook import tqdm\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "\n",
    "from pymilvus import CollectionSchema, FieldSchema, DataType, MilvusClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Milvus client\n",
    "client = MilvusClient(uri=\"http://localhost:19530\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['articles_collection_L2',\n",
       " 'articles_collection_IP',\n",
       " 'articles_collection_COSINE']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_metric_types(df_articles, partitioned_entities, metric_types, embeddings_dim):\n",
    "    # Dictionary to store the created collections\n",
    "    collections = {}\n",
    "\n",
    "    # Iterate over different metric types (L2, IP, COSINE)\n",
    "    for metric_type in metric_types:\n",
    "        collection_name = f\"articles_collectionPartition_{metric_type}\"\n",
    "\n",
    "        # Check if the collection already exists and drop it if necessary\n",
    "        if client.has_collection(collection_name):\n",
    "            print(f\"Collection {collection_name} already exists. Dropping the collection...\\n\")\n",
    "            client.drop_collection(collection_name)\n",
    "        \n",
    "        # Define the fields of the collection\n",
    "        id_field = FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True)\n",
    "        text_field = FieldSchema(name=\"article\", dtype=DataType.VARCHAR, max_length=65535)\n",
    "        reference_field = FieldSchema(name=\"reference\", dtype=DataType.VARCHAR, max_length=1000)\n",
    "        embedding_field = FieldSchema(name=\"embedding_articles\", dtype=DataType.FLOAT16_VECTOR, dim=embeddings_dim)\n",
    "\n",
    "        # Define the schema\n",
    "        schema = CollectionSchema(fields=[id_field, text_field, reference_field, embedding_field], description=f\"Collection for {metric_type} benchmark\")\n",
    "        \n",
    "        # Create the collection\n",
    "        client.create_collection(collection_name=collection_name, schema=schema)\n",
    "        \n",
    "        # Create partitions based on unique codes in df_articles\n",
    "        codes = df_articles['normalized_code'].unique()\n",
    "        for code in codes:\n",
    "            client.create_partition(collection_name=collection_name, partition_name=code)\n",
    "        \n",
    "        # Insert entities into the partitions before creating the index\n",
    "        for partition, entities in partitioned_entities.items():\n",
    "            print(f\"Inserting entities into partition: {partition}\")\n",
    "            try:\n",
    "                client.insert(data=entities, collection_name=collection_name, partition_name=partition)\n",
    "            except Exception as e:\n",
    "                print(f\"Error during insertion for partition {partition}: {e}\")\n",
    "        \n",
    "        # Create the index with the metric type (only using FLAT index)\n",
    "        index_params = MilvusClient.prepare_index_params()\n",
    "        index_params.add_index(\n",
    "            field_name=\"embedding_articles\",\n",
    "            metric_type=metric_type,  # Change only the metric type (L2, IP, COSINE)\n",
    "            index_type=\"FLAT\",  # Always use FLAT index\n",
    "            index_name=\"vector_index\",\n",
    "            params={}  # No additional parameters needed for FLAT index\n",
    "        )\n",
    "        \n",
    "        # Create the index on the collection after inserting the entities\n",
    "        try:\n",
    "            client.create_index(\n",
    "                collection_name=collection_name,\n",
    "                index_params=index_params,\n",
    "                sync=True  # Wait for index creation to complete\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to create an index on collection: {collection_name}\")\n",
    "            print(e)\n",
    "            continue  # Skip this index and continue with the next one\n",
    "\n",
    "        # Store the created collection in the dictionary\n",
    "        collections[metric_type] = collection_name\n",
    "\n",
    "    print(\"\\n\\nBenchmark completed for all metric types.\")\n",
    "\n",
    "    # Return the dictionary containing the collections\n",
    "    return collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pd.read_csv(\"articles.csv\")\n",
    "\n",
    "\n",
    "def normalize_partition_name(name):\n",
    "    # Remplacer les espaces et les tirets par des underscores\n",
    "    name = re.sub(r'\\s+|-', '_', name)\n",
    "    # Supprimer les accents et caractères spéciaux\n",
    "    name = re.sub(r'[^a-zA-Z0-9_]', '', name)\n",
    "    return name\n",
    "\n",
    "# Appliquer cette fonction aux noms des codes\n",
    "df_articles['normalized_code'] = df_articles['code'].apply(normalize_partition_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embeddings from the JSON file\n",
    "with open('embeddings.json', 'r', encoding='utf-8') as f:\n",
    "    loaded_embeddings = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_from_file(filepath: str) -> Dict[int, np.ndarray]:\n",
    "    # Load the npz file\n",
    "    data = np.load(filepath)\n",
    "    \n",
    "    # Convert arrays back to dictionary\n",
    "    embeddings_dict = {\n",
    "        int(id_): emb for id_, emb in zip(data['ids'], data['embeddings'])\n",
    "    }\n",
    "    \n",
    "    print(f\"Successfully loaded {len(embeddings_dict)} embeddings\")\n",
    "    \n",
    "    return embeddings_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 22633 embeddings\n"
     ]
    }
   ],
   "source": [
    "embeddings = load_embeddings_from_file('embeddings_bel.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating entities with partitions: 22633it [09:43, 38.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store entities by partition\n",
    "partitioned_entities = {}\n",
    "\n",
    "# Iterate over each row of the dataframe to create entities\n",
    "for _, row in tqdm(df_articles.iterrows(), desc=\"Creating entities with partitions\"):\n",
    "    partition = row['normalized_code']\n",
    "    \n",
    "    # Find the corresponding embedding\n",
    "    embedding = next(e['embedding'] for e in loaded_embeddings if e['id'] == row['id'])\n",
    "    \n",
    "    # Create an entity with the embedding\n",
    "    entity = {\n",
    "        \"id\": row['id'],\n",
    "        \"article\": row['article'],\n",
    "        \"reference\": row['reference'],\n",
    "        \"embedding_articles\": np.array(embedding, dtype=np.float16)  #en np.array de float16 pour respecter les exigences de Milvus\n",
    "    }\n",
    "    \n",
    "    # Add entity to the list corresponding to the partition\n",
    "    if partition not in partitioned_entities:\n",
    "        partitioned_entities[partition] = []\n",
    "    partitioned_entities[partition].append(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_embeddings_in_chunks_and_partitions(\n",
    "    df_articles: pd.DataFrame,\n",
    "    loaded_embeddings: Dict[int, np.ndarray],\n",
    "    chunk_size: int = 1000\n",
    ") -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Process embeddings in chunks and organize them into partitions.\n",
    "    \n",
    "    Args:\n",
    "        df_articles: DataFrame containing article information\n",
    "        loaded_embeddings: Dictionary mapping article IDs to their embeddings\n",
    "        chunk_size: Number of rows to process in each chunk\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of processed entities organized by partitions\n",
    "    \"\"\"\n",
    "    # Initialize dictionary for partitioned entities\n",
    "    partitioned_entities = {}\n",
    "\n",
    "    # Calculate total number of chunks\n",
    "    total_chunks = (len(df_articles) + chunk_size - 1) // chunk_size\n",
    "\n",
    "    # Process data in chunks with progress bar\n",
    "    with tqdm(total=len(df_articles), desc=\"Processing entities\") as pbar:\n",
    "        for chunk_start in range(0, len(df_articles), chunk_size):\n",
    "            # Get chunk of dataframe\n",
    "            chunk_end = min(chunk_start + chunk_size, len(df_articles))\n",
    "            df_chunk = df_articles.iloc[chunk_start:chunk_end]\n",
    "\n",
    "            # Process chunk\n",
    "            for _, row in df_chunk.iterrows():\n",
    "                partition = row['normalized_code']\n",
    "                embedding = loaded_embeddings.get(row['id'])\n",
    "                if embedding is not None:\n",
    "                    entity = {\n",
    "                        \"id\": row['id'],\n",
    "                        \"article\": row['article'],\n",
    "                        \"reference\": row['reference'],\n",
    "                        \"embedding_articles\": np.array(embedding, dtype=np.float16)  # np.array of float16 to meet Milvus requirements\n",
    "                    }\n",
    "                    if partition not in partitioned_entities:\n",
    "                        partitioned_entities[partition] = []\n",
    "                    partitioned_entities[partition].append(entity)\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.update(len(df_chunk))\n",
    "\n",
    "    print(f\"Processed entities into {len(partitioned_entities)} partitions.\")\n",
    "    return partitioned_entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10b678bb193490ebb7169c104f50dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing entities:   0%|          | 0/22633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed entities into 34 partitions.\n"
     ]
    }
   ],
   "source": [
    "partitioned_entities = process_embeddings_in_chunks_and_partitions(df_articles, embeddings, chunk_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting entities into partition: Code_Bruxellois_de_lAir_du_Climat_et_de_la_Matrise_de_lEnergie\n",
      "Inserting entities into partition: Code_Bruxellois_de_lAmnagement_du_Territoire\n",
      "Inserting entities into partition: Code_Bruxellois_du_Logement\n",
      "Inserting entities into partition: Code_Civil\n",
      "Inserting entities into partition: Code_Consulaire\n",
      "Inserting entities into partition: Code_Electoral\n",
      "Inserting entities into partition: Code_Electoral_Communal_Bruxellois\n",
      "Inserting entities into partition: Code_Ferroviaire\n",
      "Inserting entities into partition: Code_Forestier\n",
      "Inserting entities into partition: Code_Judiciaire\n",
      "Inserting entities into partition: Code_Pnal\n",
      "Inserting entities into partition: Code_Pnal_Militaire\n",
      "Inserting entities into partition: Code_Pnal_Social\n",
      "Inserting entities into partition: Code_Rural\n",
      "Inserting entities into partition: Code_Rglementaire_Wallon_de_lAction_sociale_et_de_la_Sant\n",
      "Inserting entities into partition: Code_Wallon_de_lAction_sociale_et_de_la_Sant\n",
      "Inserting entities into partition: Code_Wallon_de_lAgriculture\n",
      "Inserting entities into partition: Code_Wallon_de_lEnseignement_Fondamental_et_de_lEnseignement_Secondaire\n",
      "Inserting entities into partition: Code_Wallon_de_lEnvironnement\n",
      "Inserting entities into partition: Code_Wallon_de_lHabitation_Durable\n",
      "Inserting entities into partition: Code_Wallon_du_Bien_tre_des_animaux\n",
      "Inserting entities into partition: Code_Wallon_du_Dveloppement_Territorial\n",
      "Inserting entities into partition: Code_dInstruction_Criminelle\n",
      "Inserting entities into partition: Code_de_Droit_Economique\n",
      "Inserting entities into partition: Code_de_Droit_International_Priv\n",
      "Inserting entities into partition: Code_de_lEau_intgr_au_Code_Wallon_de_lEnvironnement\n",
      "Inserting entities into partition: Code_de_la_Dmocratie_Locale_et_de_la_Dcentralisation\n",
      "Inserting entities into partition: Code_de_la_Fonction_Publique_Wallonne\n",
      "Inserting entities into partition: Code_de_la_Nationalit_Belge\n",
      "Inserting entities into partition: Code_de_la_Navigation\n",
      "Inserting entities into partition: Code_des_Socits_et_des_Associations\n",
      "Inserting entities into partition: Code_du_Bien_tre_au_Travail\n",
      "Inserting entities into partition: Codes_des_Droits_et_Taxes_Divers\n",
      "Inserting entities into partition: La_Constitution\n",
      "Inserting entities into partition: Code_Bruxellois_de_lAir_du_Climat_et_de_la_Matrise_de_lEnergie\n",
      "Inserting entities into partition: Code_Bruxellois_de_lAmnagement_du_Territoire\n",
      "Inserting entities into partition: Code_Bruxellois_du_Logement\n",
      "Inserting entities into partition: Code_Civil\n",
      "Inserting entities into partition: Code_Consulaire\n",
      "Inserting entities into partition: Code_Electoral\n",
      "Inserting entities into partition: Code_Electoral_Communal_Bruxellois\n",
      "Inserting entities into partition: Code_Ferroviaire\n",
      "Inserting entities into partition: Code_Forestier\n",
      "Inserting entities into partition: Code_Judiciaire\n",
      "Inserting entities into partition: Code_Pnal\n",
      "Inserting entities into partition: Code_Pnal_Militaire\n",
      "Inserting entities into partition: Code_Pnal_Social\n",
      "Inserting entities into partition: Code_Rural\n",
      "Inserting entities into partition: Code_Rglementaire_Wallon_de_lAction_sociale_et_de_la_Sant\n",
      "Inserting entities into partition: Code_Wallon_de_lAction_sociale_et_de_la_Sant\n",
      "Inserting entities into partition: Code_Wallon_de_lAgriculture\n",
      "Inserting entities into partition: Code_Wallon_de_lEnseignement_Fondamental_et_de_lEnseignement_Secondaire\n",
      "Inserting entities into partition: Code_Wallon_de_lEnvironnement\n",
      "Inserting entities into partition: Code_Wallon_de_lHabitation_Durable\n",
      "Inserting entities into partition: Code_Wallon_du_Bien_tre_des_animaux\n",
      "Inserting entities into partition: Code_Wallon_du_Dveloppement_Territorial\n",
      "Inserting entities into partition: Code_dInstruction_Criminelle\n",
      "Inserting entities into partition: Code_de_Droit_Economique\n",
      "Inserting entities into partition: Code_de_Droit_International_Priv\n",
      "Inserting entities into partition: Code_de_lEau_intgr_au_Code_Wallon_de_lEnvironnement\n",
      "Inserting entities into partition: Code_de_la_Dmocratie_Locale_et_de_la_Dcentralisation\n",
      "Inserting entities into partition: Code_de_la_Fonction_Publique_Wallonne\n",
      "Inserting entities into partition: Code_de_la_Nationalit_Belge\n",
      "Inserting entities into partition: Code_de_la_Navigation\n",
      "Inserting entities into partition: Code_des_Socits_et_des_Associations\n",
      "Inserting entities into partition: Code_du_Bien_tre_au_Travail\n",
      "Inserting entities into partition: Codes_des_Droits_et_Taxes_Divers\n",
      "Inserting entities into partition: La_Constitution\n",
      "Inserting entities into partition: Code_Bruxellois_de_lAir_du_Climat_et_de_la_Matrise_de_lEnergie\n",
      "Inserting entities into partition: Code_Bruxellois_de_lAmnagement_du_Territoire\n",
      "Inserting entities into partition: Code_Bruxellois_du_Logement\n",
      "Inserting entities into partition: Code_Civil\n",
      "Inserting entities into partition: Code_Consulaire\n",
      "Inserting entities into partition: Code_Electoral\n",
      "Inserting entities into partition: Code_Electoral_Communal_Bruxellois\n",
      "Inserting entities into partition: Code_Ferroviaire\n",
      "Inserting entities into partition: Code_Forestier\n",
      "Inserting entities into partition: Code_Judiciaire\n",
      "Inserting entities into partition: Code_Pnal\n",
      "Inserting entities into partition: Code_Pnal_Militaire\n",
      "Inserting entities into partition: Code_Pnal_Social\n",
      "Inserting entities into partition: Code_Rural\n",
      "Inserting entities into partition: Code_Rglementaire_Wallon_de_lAction_sociale_et_de_la_Sant\n",
      "Inserting entities into partition: Code_Wallon_de_lAction_sociale_et_de_la_Sant\n",
      "Inserting entities into partition: Code_Wallon_de_lAgriculture\n",
      "Inserting entities into partition: Code_Wallon_de_lEnseignement_Fondamental_et_de_lEnseignement_Secondaire\n",
      "Inserting entities into partition: Code_Wallon_de_lEnvironnement\n",
      "Inserting entities into partition: Code_Wallon_de_lHabitation_Durable\n",
      "Inserting entities into partition: Code_Wallon_du_Bien_tre_des_animaux\n",
      "Inserting entities into partition: Code_Wallon_du_Dveloppement_Territorial\n",
      "Inserting entities into partition: Code_dInstruction_Criminelle\n",
      "Inserting entities into partition: Code_de_Droit_Economique\n",
      "Inserting entities into partition: Code_de_Droit_International_Priv\n",
      "Inserting entities into partition: Code_de_lEau_intgr_au_Code_Wallon_de_lEnvironnement\n",
      "Inserting entities into partition: Code_de_la_Dmocratie_Locale_et_de_la_Dcentralisation\n",
      "Inserting entities into partition: Code_de_la_Fonction_Publique_Wallonne\n",
      "Inserting entities into partition: Code_de_la_Nationalit_Belge\n",
      "Inserting entities into partition: Code_de_la_Navigation\n",
      "Inserting entities into partition: Code_des_Socits_et_des_Associations\n",
      "Inserting entities into partition: Code_du_Bien_tre_au_Travail\n",
      "Inserting entities into partition: Codes_des_Droits_et_Taxes_Divers\n",
      "Inserting entities into partition: La_Constitution\n",
      "\n",
      "\n",
      "Benchmark completed for all metric types.\n"
     ]
    }
   ],
   "source": [
    "metric_types = [\"L2\", \"IP\", \"COSINE\"]\n",
    "index_types = [\"FLAT\"]\n",
    "embeddings_dim = 1024  \n",
    "\n",
    "collections = benchmark_metric_types(df_articles, partitioned_entities, metric_types, embeddings_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L2': 'articles_collectionPartition_L2',\n",
       " 'IP': 'articles_collectionPartition_IP',\n",
       " 'COSINE': 'articles_collectionPartition_COSINE'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions = pd.read_csv(\"questions_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_bel = SentenceTransformer('Lajavaness/bilingual-embedding-large', trust_remote_code=True, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c018ea738a48ba92e1887f7175c459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mthia\\anaconda3\\envs\\AI_App\\Lib\\site-packages\\FlagEmbedding\\BGE_M3\\modeling.py:335: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  colbert_state_dict = torch.load(os.path.join(model_dir, 'colbert_linear.pt'), map_location='cpu')\n",
      "c:\\Users\\mthia\\anaconda3\\envs\\AI_App\\Lib\\site-packages\\FlagEmbedding\\BGE_M3\\modeling.py:336: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sparse_state_dict = torch.load(os.path.join(model_dir, 'sparse_linear.pt'), map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "bge_m3 = BGEM3FlagModel('BAAI/bge-m3',  \n",
    "                       use_fp16=True, \n",
    "                       device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(article):\n",
    "    embedding = bge_m3.encode([article], batch_size=12, max_length=8*1024)[\"dense_vecs\"]\n",
    "    return embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from typing import Union, List\n",
    "import torch\n",
    "\n",
    "def generate_embedding(\n",
    "    article: Union[str, List[str]],\n",
    "    model: SentenceTransformer,\n",
    "    batch_size: int = 32,\n",
    "    max_length: int = 512,\n",
    "    device: str = None\n",
    ") -> np.ndarray:\n",
    "\n",
    "    # Set device\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Ensure model is on correct device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Convert single article to list if necessary\n",
    "    if isinstance(article, str):\n",
    "        articles = [article]\n",
    "    else:\n",
    "        articles = article\n",
    "    \n",
    "    # Generate embeddings\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.encode(\n",
    "            articles,\n",
    "            batch_size=batch_size,\n",
    "            show_progress_bar=False,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True,  # Normalize for cosine similarity\n",
    "            max_length=max_length,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "    # Convert embeddings to float16\n",
    "    embeddings = embeddings.astype(np.float16)\n",
    "    \n",
    "    # Return single embedding if input was single article\n",
    "    if isinstance(article, str):\n",
    "        return embeddings[0]\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions = pd.read_csv('questions_train.csv')\n",
    "\n",
    "#concat df_questions['question'] + df_questions['extra_description']\n",
    "\n",
    "df_questions['complet_question'] = df_questions['question'] + df_questions['extra_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = generate_embedding(\n",
    "    article= df_questions['complet_question'].iloc[0],\n",
    "    model=model_bel,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03096 , -0.004353,  0.03195 , ..., -0.0366  , -0.02815 ,\n",
       "       -0.0423  ], dtype=float16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_default', 'Code_Bruxellois_de_lAir_du_Climat_et_de_la_Matrise_de_lEnergie', 'Code_Bruxellois_de_lAmnagement_du_Territoire', 'Code_Bruxellois_du_Logement', 'Code_Civil', 'Code_Consulaire', 'Code_Electoral', 'Code_Electoral_Communal_Bruxellois', 'Code_Ferroviaire', 'Code_Forestier', 'Code_Judiciaire', 'Code_Pnal', 'Code_Pnal_Militaire', 'Code_Pnal_Social', 'Code_Rural', 'Code_Rglementaire_Wallon_de_lAction_sociale_et_de_la_Sant', 'Code_Wallon_de_lAction_sociale_et_de_la_Sant', 'Code_Wallon_de_lAgriculture', 'Code_Wallon_de_lEnseignement_Fondamental_et_de_lEnseignement_Secondaire', 'Code_Wallon_de_lEnvironnement', 'Code_Wallon_de_lHabitation_Durable', 'Code_Wallon_du_Bien_tre_des_animaux', 'Code_Wallon_du_Dveloppement_Territorial', 'Code_dInstruction_Criminelle', 'Code_de_Droit_Economique', 'Code_de_Droit_International_Priv', 'Code_de_lEau_intgr_au_Code_Wallon_de_lEnvironnement', 'Code_de_la_Dmocratie_Locale_et_de_la_Dcentralisation', 'Code_de_la_Fonction_Publique_Wallonne', 'Code_de_la_Nationalit_Belge', 'Code_de_la_Navigation', 'Code_des_Socits_et_des_Associations', 'Code_du_Bien_tre_au_Travail', 'Codes_des_Droits_et_Taxes_Divers', 'La_Constitution']\n"
     ]
    }
   ],
   "source": [
    "res = client.list_partitions(collection_name=\"articles_collectionPartition_L2\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing collection: articles_collection_L2 with metric type: L2\n",
      "Index info for L2: {'index_type': 'FLAT', 'metric_type': 'L2', 'field_name': 'embedding_articles', 'index_name': 'vector_index', 'total_rows': 0, 'indexed_rows': 0, 'pending_index_rows': 0, 'state': 'Finished'}\n",
      "Results for L2:\n",
      "[\n",
      "   {\n",
      "      \"id\": 22233,\n",
      "      \"distance\": 0.7523195743560791,\n",
      "      \"entity\": {\n",
      "         \"id\": 22233,\n",
      "         \"reference\": \"Art. X.5-9, Code du Bien-être au Travail (Livre X, Titre 5)\"\n",
      "      }\n",
      "   },\n",
      "   {\n",
      "      \"id\": 22176,\n",
      "      \"distance\": 0.8595061302185059,\n",
      "      \"entity\": {\n",
      "         \"id\": 22176,\n",
      "         \"reference\": \"Art. X.1-1, Code du Bien-être au Travail (Livre X, Titre 1er)\"\n",
      "      }\n",
      "   },\n",
      "   {\n",
      "      \"id\": 21110,\n",
      "      \"distance\": 0.8613051772117615,\n",
      "      \"entity\": {\n",
      "         \"id\": 21110,\n",
      "         \"reference\": \"Art. I.4-68, Code du Bien-être au Travail (Livre Ier, Titre 4, Chapitre V, Section 6)\"\n",
      "      }\n",
      "   }\n",
      "]\n",
      "Testing collection: articles_collection_IP with metric type: IP\n",
      "Index info for IP: {'index_type': 'FLAT', 'metric_type': 'IP', 'field_name': 'embedding_articles', 'index_name': 'vector_index', 'total_rows': 0, 'indexed_rows': 0, 'pending_index_rows': 0, 'state': 'Finished'}\n",
      "Results for IP:\n",
      "[\n",
      "   {\n",
      "      \"id\": 22233,\n",
      "      \"distance\": 0.6235238313674927,\n",
      "      \"entity\": {\n",
      "         \"id\": 22233,\n",
      "         \"reference\": \"Art. X.5-9, Code du Bien-être au Travail (Livre X, Titre 5)\"\n",
      "      }\n",
      "   },\n",
      "   {\n",
      "      \"id\": 22176,\n",
      "      \"distance\": 0.5699306726455688,\n",
      "      \"entity\": {\n",
      "         \"id\": 22176,\n",
      "         \"reference\": \"Art. X.1-1, Code du Bien-être au Travail (Livre X, Titre 1er)\"\n",
      "      }\n",
      "   },\n",
      "   {\n",
      "      \"id\": 21110,\n",
      "      \"distance\": 0.5689291954040527,\n",
      "      \"entity\": {\n",
      "         \"id\": 21110,\n",
      "         \"reference\": \"Art. I.4-68, Code du Bien-être au Travail (Livre Ier, Titre 4, Chapitre V, Section 6)\"\n",
      "      }\n",
      "   }\n",
      "]\n",
      "Testing collection: articles_collection_COSINE with metric type: COSINE\n",
      "Index info for COSINE: {'index_type': 'FLAT', 'metric_type': 'COSINE', 'field_name': 'embedding_articles', 'index_name': 'vector_index', 'total_rows': 0, 'indexed_rows': 0, 'pending_index_rows': 0, 'state': 'Finished'}\n",
      "Results for COSINE:\n",
      "[\n",
      "   {\n",
      "      \"id\": 22233,\n",
      "      \"distance\": 0.6237211227416992,\n",
      "      \"entity\": {\n",
      "         \"id\": 22233,\n",
      "         \"reference\": \"Art. X.5-9, Code du Bien-être au Travail (Livre X, Titre 5)\"\n",
      "      }\n",
      "   },\n",
      "   {\n",
      "      \"id\": 22176,\n",
      "      \"distance\": 0.5701108574867249,\n",
      "      \"entity\": {\n",
      "         \"id\": 22176,\n",
      "         \"reference\": \"Art. X.1-1, Code du Bien-être au Travail (Livre X, Titre 1er)\"\n",
      "      }\n",
      "   },\n",
      "   {\n",
      "      \"id\": 21110,\n",
      "      \"distance\": 0.5691672563552856,\n",
      "      \"entity\": {\n",
      "         \"id\": 21110,\n",
      "         \"reference\": \"Art. I.4-68, Code du Bien-être au Travail (Livre Ier, Titre 4, Chapitre V, Section 6)\"\n",
      "      }\n",
      "   }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Partition sur laquelle effectuer la recherche\n",
    "# partitions = res[1:]  # Liste des partitions à charger\n",
    "\n",
    "partitions = [\"Code_du_Bien_tre_au_Travail\", \"Code_des_Socits_et_des_Associations\"]\n",
    "\n",
    "# Vecteur de la question à tester\n",
    "query_vector = generate_embedding(df_questions['question'].iloc[0])\n",
    "\n",
    "# Paramètres de recherche uniquement pour FLAT, en variant les métriques\n",
    "search_params = {\n",
    "    'L2': {\"metric_type\": \"L2\", \"params\": {}},      # Distance euclidienne\n",
    "    'COSINE': {\"metric_type\": \"COSINE\", \"params\": {}},  # Distance cosinus\n",
    "    'IP': {\"metric_type\": \"IP\", \"params\": {}},      # Produit scalaire\n",
    "}\n",
    "\n",
    "# Résultats de performance\n",
    "performance_results = {}\n",
    "\n",
    "# Boucle pour tester chaque métrique\n",
    "for metric_type, collection_name in collections.items():\n",
    "    print(f\"Testing collection: {collection_name} with metric type: {metric_type}\")\n",
    "\n",
    "    # Charger les partitions pour la collection\n",
    "    client.load_partitions(collection_name=collection_name, partition_names=partitions)\n",
    "\n",
    "    # Récupérer les informations sur l'index\n",
    "    index_info = client.describe_index(collection_name=collection_name, index_name=\"vector_index\")\n",
    "    print(f\"Index info for {metric_type}: {index_info}\")\n",
    "\n",
    "    # Effectuer la recherche avec la métrique correspondante\n",
    "    search_results = client.search(\n",
    "        collection_name=collection_name,\n",
    "        data=[query_vector],\n",
    "        partition_names=partitions,\n",
    "        limit=3,\n",
    "        search_params=search_params[metric_type],  # Utiliser les paramètres de la métrique en cours\n",
    "        output_fields=['id', 'reference']\n",
    "    )\n",
    "\n",
    "    # Formater et afficher les résultats\n",
    "    formatted_result = json.dumps(search_results[0], indent=3, ensure_ascii=False)\n",
    "    print(f\"Results for {metric_type}:\\n{formatted_result}\")\n",
    "    \n",
    "    # Enregistrer les résultats dans le dictionnaire\n",
    "    performance_results[metric_type] = search_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: 22225,22226,22227,22228,22229,22230,22231,22232,22233,22234 \n",
      "\n",
      "metric Type: L2 - results: [22233, 22176, 21110] - distances: [0.7523195743560791, 0.8595061302185059, 0.8613051772117615]\n",
      "\n",
      "\n",
      "metric Type: IP - results: [22233, 22176, 21110] - distances: [0.6235238313674927, 0.5699306726455688, 0.5689291954040527]\n",
      "\n",
      "\n",
      "metric Type: COSINE - results: [22233, 22176, 21110] - distances: [0.6237211227416992, 0.5701108574867249, 0.5691672563552856]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = df_questions['article_ids'].iloc[0]\n",
    "print(f\"Labels: {labels} \\n\")\n",
    "\n",
    "\n",
    "# Affichage des résultats pour chaque index\n",
    "for index_type, result in performance_results.items():\n",
    "    list_ids = [result[\"entity\"][\"id\"] for result in result[0]]\n",
    "    list_prods = [result[\"distance\"] for result in result[0]]\n",
    "    print(f\"metric Type: {index_type} - results: {list_ids} - distances: {list_prods}\")\n",
    "\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing collection: articles_collectionPartition_L2 with metric type: L2\n",
      "Index info for L2: {'index_type': 'FLAT', 'metric_type': 'L2', 'field_name': 'embedding_articles', 'index_name': 'vector_index', 'total_rows': 0, 'indexed_rows': 0, 'pending_index_rows': 0, 'state': 'Finished'}\n",
      "Results for L2:\n",
      "[\n",
      "   {\n",
      "      \"id\": 21092,\n",
      "      \"distance\": 0.8355220556259155,\n",
      "      \"entity\": {\n",
      "         \"id\": 21092,\n",
      "         \"reference\": \"Art. I.4-50, Code du Bien-être au Travail (Livre Ier, Titre 4, Chapitre V, Section 2)\"\n",
      "      }\n",
      "   },\n",
      "   {\n",
      "      \"id\": 22225,\n",
      "      \"distance\": 0.8465765714645386,\n",
      "      \"entity\": {\n",
      "         \"id\": 22225,\n",
      "         \"reference\": \"Art. X.5-1, Code du Bien-être au Travail (Livre X, Titre 5)\"\n",
      "      }\n",
      "   },\n",
      "   {\n",
      "      \"id\": 21111,\n",
      "      \"distance\": 0.9035404324531555,\n",
      "      \"entity\": {\n",
      "         \"id\": 21111,\n",
      "         \"reference\": \"Art. I.4-69, Code du Bien-être au Travail (Livre Ier, Titre 4, Chapitre V, Section 7)\"\n",
      "      }\n",
      "   }\n",
      "]\n",
      "Testing collection: articles_collectionPartition_IP with metric type: IP\n",
      "Index info for IP: {'index_type': 'FLAT', 'metric_type': 'IP', 'field_name': 'embedding_articles', 'index_name': 'vector_index', 'total_rows': 0, 'indexed_rows': 0, 'pending_index_rows': 0, 'state': 'Finished'}\n",
      "Results for IP:\n",
      "[\n",
      "   {\n",
      "      \"id\": 21092,\n",
      "      \"distance\": 0.5822518467903137,\n",
      "      \"entity\": {\n",
      "         \"id\": 21092,\n",
      "         \"reference\": \"Art. I.4-50, Code du Bien-être au Travail (Livre Ier, Titre 4, Chapitre V, Section 2)\"\n",
      "      }\n",
      "   },\n",
      "   {\n",
      "      \"id\": 22225,\n",
      "      \"distance\": 0.5766925811767578,\n",
      "      \"entity\": {\n",
      "         \"id\": 22225,\n",
      "         \"reference\": \"Art. X.5-1, Code du Bien-être au Travail (Livre X, Titre 5)\"\n",
      "      }\n",
      "   },\n",
      "   {\n",
      "      \"id\": 21111,\n",
      "      \"distance\": 0.5482323169708252,\n",
      "      \"entity\": {\n",
      "         \"id\": 21111,\n",
      "         \"reference\": \"Art. I.4-69, Code du Bien-être au Travail (Livre Ier, Titre 4, Chapitre V, Section 7)\"\n",
      "      }\n",
      "   }\n",
      "]\n",
      "Testing collection: articles_collectionPartition_COSINE with metric type: COSINE\n",
      "Index info for COSINE: {'index_type': 'FLAT', 'metric_type': 'COSINE', 'field_name': 'embedding_articles', 'index_name': 'vector_index', 'total_rows': 0, 'indexed_rows': 0, 'pending_index_rows': 0, 'state': 'Finished'}\n",
      "Results for COSINE:\n",
      "[\n",
      "   {\n",
      "      \"id\": 21092,\n",
      "      \"distance\": 0.582244336605072,\n",
      "      \"entity\": {\n",
      "         \"id\": 21092,\n",
      "         \"reference\": \"Art. I.4-50, Code du Bien-être au Travail (Livre Ier, Titre 4, Chapitre V, Section 2)\"\n",
      "      }\n",
      "   },\n",
      "   {\n",
      "      \"id\": 22225,\n",
      "      \"distance\": 0.5767034888267517,\n",
      "      \"entity\": {\n",
      "         \"id\": 22225,\n",
      "         \"reference\": \"Art. X.5-1, Code du Bien-être au Travail (Livre X, Titre 5)\"\n",
      "      }\n",
      "   },\n",
      "   {\n",
      "      \"id\": 21111,\n",
      "      \"distance\": 0.5482308864593506,\n",
      "      \"entity\": {\n",
      "         \"id\": 21111,\n",
      "         \"reference\": \"Art. I.4-69, Code du Bien-être au Travail (Livre Ier, Titre 4, Chapitre V, Section 7)\"\n",
      "      }\n",
      "   }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Partition sur laquelle effectuer la recherche\n",
    "# partitions = res[1:]  # Liste des partitions à charger\n",
    "\n",
    "partitions = [\"Code_du_Bien_tre_au_Travail\", \"Code_des_Socits_et_des_Associations\"]\n",
    "\n",
    "# Paramètres de recherche uniquement pour FLAT, en variant les métriques\n",
    "search_params = {\n",
    "    'L2': {\"metric_type\": \"L2\", \"params\": {}},      # Distance euclidienne\n",
    "    'COSINE': {\"metric_type\": \"COSINE\", \"params\": {}},  # Distance cosinus\n",
    "    'IP': {\"metric_type\": \"IP\", \"params\": {}},      # Produit scalaire\n",
    "}\n",
    "\n",
    "# Résultats de performance\n",
    "performance_results = {}\n",
    "\n",
    "# Boucle pour tester chaque métrique\n",
    "for metric_type, collection_name in collections.items():\n",
    "    print(f\"Testing collection: {collection_name} with metric type: {metric_type}\")\n",
    "\n",
    "    # Charger les partitions pour la collection\n",
    "    client.load_partitions(collection_name=collection_name, partition_names=partitions)\n",
    "\n",
    "    # Récupérer les informations sur l'index\n",
    "    index_info = client.describe_index(collection_name=collection_name, index_name=\"vector_index\")\n",
    "    print(f\"Index info for {metric_type}: {index_info}\")\n",
    "\n",
    "    # Effectuer la recherche avec la métrique correspondante\n",
    "    search_results = client.search(\n",
    "        collection_name=collection_name,\n",
    "        data=[query_vector],\n",
    "        partition_names=partitions,\n",
    "        limit=3,\n",
    "        search_params=search_params[metric_type],  # Utiliser les paramètres de la métrique en cours\n",
    "        output_fields=['id', 'reference']\n",
    "    )\n",
    "\n",
    "    # Formater et afficher les résultats\n",
    "    formatted_result = json.dumps(search_results[0], indent=3, ensure_ascii=False)\n",
    "    print(f\"Results for {metric_type}:\\n{formatted_result}\")\n",
    "    \n",
    "    # Enregistrer les résultats dans le dictionnaire\n",
    "    performance_results[metric_type] = search_results\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_App",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
