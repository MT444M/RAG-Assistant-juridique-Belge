{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "from my_token import token_key\n",
    "from transformers import BitsAndBytesConfig\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17da8d152430436dab57d5b9f8ccff38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"cuda\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Une excellente question!\n",
      "\n",
      "Dans la jurisprudence, l'objet de la loi est un concept fondamental qui définit la fonction et les objectifs de la loi dans un pays. L'objet de la loi est souvent défini comme le but ultime pour lequel la loi est créée et appliquée.\n",
      "\n",
      "Selon la théorie juridique classique, l'objet de la loi est de protéger les droits et libertés des individus, de maintenir l'ordre social et de promouvoir le bien-être général de la société. La loi est censée être une règle générale qui réglemente les relations entre les individus et entre les individus et l'État, en garantissant la stabilité, la sécurité et la justice.\n",
      "\n",
      "Plus spécifiquement, l'objet de la loi peut être défini comme suit :\n",
      "\n",
      "* Protéger les droits fondamentaux des individus, tels que la liberté d'expression, la liberté de réunion et la sécurité personnelle.\n",
      "* Maintenir l'ordre public et prévenir les crimes et les delits.\n",
      "* Protéger les intérêts des particuliers, tels que\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"tu es un expert en jurisprudence\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quel est l'objet de la loi dans un pays?\"},\n",
    "]\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " écrit une fonction en python qui génére une liste aléatoire, puis enlève doublons, et le trie  de manière à ce que le plus petit nombre soit en premier. \n",
      "\n",
      "Exemple de liste : [12, 5, 8, 10, 15, 3, 7, 11, 18, 9]\n",
      "\n",
      "La fonction devrait également prendre en compte les nombres qui sont à la même valeur, mais qui ne sont pas dans l'ordre correct.\n",
      "\n",
      "Exemple de liste : [3, 3, 5, 7, 7, 8, 9, 10, 11, 12, 15, 18]\n",
      "\n",
      "La fonction devrait également prendre en compte les nombres qui sont à la même valeur, mais qui ne sont pas dans l'ordre correct.\n",
      "\n",
      "Voici un exemple de code que j'ai écrit pour générer la liste aléatoire :\n",
      "\n",
      "```python\n",
      "import random\n",
      "\n",
      "def generate_list():\n",
      "    lst = [random.randint(1, 100) for _ in range(10)]\n",
      "    return lst\n",
      "\n",
      "lst = generate_list()\n",
      "print(lst)\n",
      "```\n",
      "\n",
      "Voici un exemple de code que j'ai écrit pour enlever les doublons :\n",
      "\n",
      "```python\n",
      "def remove_duplicates(lst):\n",
      "    return list(set(lst))\n",
      "\n",
      "lst = remove_duplicates(lst)\n",
      "print(lst)\n",
      "```\n",
      "\n",
      "Voici un\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer(\" écrit une fonction en python qui génére une liste aléatoire, puis enlève doublons, et le trie \",  return_tensors=\"pt\").to(0)\n",
    "\n",
    "out = model.generate(**text, \n",
    "                    max_new_tokens=256,\n",
    "                    pad_token_id=tokenizer.eos_token_id,\n",
    "                      )\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=True ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_App",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
